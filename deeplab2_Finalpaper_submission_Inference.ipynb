{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplab2-Finalpaper_submission-Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNYEw9sRbn29qEGqcTh3bJn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssnirgudkar/Datasetpaper-final/blob/main/deeplab2_Finalpaper_submission_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW3lSbsBxFzp"
      },
      "source": [
        "## Use this version as the most final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoAs-oCSzGI6"
      },
      "source": [
        "## we have to keep batchsize = 2 or more. It does not run with batch size 1. Image will be resized to 512*512\n",
        "##changed mask datatype to uint16 from uint8. segments.ai masks are uint16. else it reads masks as 0\n",
        "##the resize was changed to nearest. but we can check if thats needed. bilinear is default. So we can try to keep it as bilinera and that shld also work. With this run, objects were not coming up well. objects and background was getting mixed\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaETn9Z21S9y"
      },
      "source": [
        "# https://keras.io/examples/vision/deeplabv3_plus/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl9XF-Fty5RZ",
        "outputId": "7cb301f7-0d6f-4aae-acf6-00bba3b4f3fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "print(K.image_data_format()) # print current format\n",
        "#K.set_image_data_format('channels_last') # set format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBKEReZCZHYt",
        "outputId": "536f6148-c305-4359-bb12-1042c14ce9f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "channels_last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove files \n",
        "#!ls /content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/program/*runrevised*.png \n",
        "#!ls /content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/picture/*runrevised*.png \n",
        "\n",
        "#!rm /content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/program/*runreviseddata*.png \n",
        "#!rm /content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/picture/*--runreviseddata-*.png \n",
        "\n",
        "#!rm /content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/program/*--test-*.png \n",
        "#!rm /content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/picture/*--test-*.png "
      ],
      "metadata": {
        "id": "pN5zfOV9S2sx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/test.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/testannot.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "'''\n",
        "# Zip file with handpicked test images\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/select_test_images.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "# Zip file with masks of handpicked test images\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/select_test_masks.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "# copy the select_test_images and masks in test and testannot respectively \n",
        "!cp /content/IRDatasetFinal/select_test_images/*.png /content/IRDatasetFinal/test\n",
        "!cp /content/IRDatasetFinal/select_test_masks/*.png /content/IRDatasetFinal/testannot\n",
        "'''"
      ],
      "metadata": {
        "id": "ClQ6pwk4y6Cv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "10716b38-51fd-46d3-feb5-7b7ddc00bc4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Zip file with handpicked test images\\nzip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/select_test_images.zip\", \"r\")\\nzip_ref.extractall(\"/content/IRDatasetFinal\")\\nzip_ref.close()\\n\\n# Zip file with masks of handpicked test images\\nzip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/select_test_masks.zip\", \"r\")\\nzip_ref.extractall(\"/content/IRDatasetFinal\")\\nzip_ref.close()\\n\\n# copy the select_test_images and masks in test and testannot respectively \\n!cp /content/IRDatasetFinal/select_test_images/*.png /content/IRDatasetFinal/test\\n!cp /content/IRDatasetFinal/select_test_masks/*.png /content/IRDatasetFinal/testannot\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "APP_FOLDER = '/content/IRDatasetFinal/test'\n",
        "totalFiles = 0\n",
        "totalDir = 0\n",
        "\n",
        "for base, dirs, files in os.walk(APP_FOLDER):\n",
        "    print('Searching in : ',base)\n",
        "    for directories in dirs:\n",
        "        totalDir += 1\n",
        "    for Files in files:\n",
        "        totalFiles += 1\n",
        "   \n",
        "\n",
        "print('Total number of files',totalFiles)\n",
        "print('Total Number of directories',totalDir)\n",
        "print('Total:',(totalDir + totalFiles))"
      ],
      "metadata": {
        "id": "vJvUv-g7l1Qy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43dc1458-6d86-4e4b-8561-b9212e4536c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching in :  /content/IRDatasetFinal/test\n",
            "Total number of files 4508\n",
            "Total Number of directories 0\n",
            "Total: 4508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Now remove images that are not pure (rotated, mirrored etc from the test and testannot folders) \n",
        "# as we do not want to use them for testing \n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "test_dir = \"/content/IRDatasetFinal/test\"\n",
        "test_mask_dir = \"/content/IRDatasetFinal/testannot\"\n",
        "# Move rotated & mirrored files into tmp directory\n",
        "# The format of these files is aXXX_XXX_XX.png and aXXX_XXX_XX_XX.png\n",
        "# Number of underscores is 2 or 3\n",
        "dest_test_dir = \"/content/IRDatasetFinal/test_tmp\"\n",
        "dest_mask_dir = \"/content/IRDatasetFinal/testannot_tmp\"\n",
        "\n",
        "# Move non-augmented files from test directory into a temporary directory\n",
        "if (False == os.path.exists(dest_test_dir)):\n",
        "  os.mkdir(dest_test_dir)\n",
        "if (False == os.path.exists(dest_mask_dir)):\n",
        "  os.mkdir(dest_mask_dir)\n",
        "\n",
        "\n",
        "for eachFile in os.listdir(test_dir):\n",
        "  numUnderscores = eachFile.count('_')\n",
        "  if (numUnderscores > 1):\n",
        "    # File names in image & mask directories are identical so move both files in one shot!\n",
        "    shutil.move(os.path.join(test_dir, eachFile), os.path.join(dest_test_dir))\n",
        "    shutil.move(os.path.join(test_mask_dir, eachFile), os.path.join(dest_mask_dir))\n",
        "    \n",
        "'''\n",
        "    for eachFile in os.listdir(test_mask_dir):\n",
        "      numUnderscores = eachFile.count('_')\n",
        "      if (numUnderscores > 1):\n",
        "        # File names in image & mask directories are identical so move both files in one shot!\n",
        "        shutil.move(os.path.join(test_mask_dir, eachFile), os.path.join(dest_mask_dir))\n",
        "'''\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "C4o-MCy5l2FL",
        "outputId": "9ad15c37-06d4-4eda-d778-3f4d863825b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n    for eachFile in os.listdir(test_mask_dir):\\n      numUnderscores = eachFile.count('_')\\n      if (numUnderscores > 1):\\n        # File names in image & mask directories are identical so move both files in one shot!\\n        shutil.move(os.path.join(test_mask_dir, eachFile), os.path.join(dest_mask_dir))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# check if test images are present in train / validation folder \n",
        "\n",
        "# Zip file with masks of handpicked test images\n",
        "import glob \n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/train.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/val.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "import os\n",
        "from os.path import exists\n",
        "\n",
        "file_present = 0\n",
        "for eachFile in os.listdir('/content/IRDatasetFinal/test'):\n",
        "    filename = eachFile.split(\".\")[0]  \n",
        "    #print(\"name of file\", filename)\n",
        "    \n",
        "    count_train = 0 \n",
        "    count_val = 0 \n",
        "     \n",
        "    for file in os.listdir(\"/content/IRDatasetFinal/train/\"):\n",
        "      if file.startswith(filename):\n",
        "         #print(\"File exists in train directory\", filename, os.path.join(\"/content/IRDatasetFinal/train/\", file))\n",
        "         count_train = 1 \n",
        "      if count_train == 1:\n",
        "        break \n",
        "\n",
        "    for file in os.listdir(\"/content/IRDatasetFinal/val/\"):\n",
        "      if file.startswith(filename):\n",
        "        #print(\"File exists in val directory\", filename, os.path.join(\"/content/IRDatasetFinal/val/\", file))\n",
        "        count_val = 1 \n",
        "      if count_val ==1:\n",
        "        break\n",
        "    if count_train ==1 or count_val == 1:\n",
        "      file_present = file_present + 1 \n",
        "    else:\n",
        "      print(\"files that are not present in train or val\", filename)\n",
        "\n",
        "print(\"total files from 325 that are either in val or train dir are\", file_present)\n",
        "\n",
        "'''\n",
        "    if filename in glob.glob('/content/IRDatasetFinal/train/*[0-9].*') == True:\n",
        "       print(\"test file exists in train directory\", filename)\n",
        "    \n",
        "    if filename in glob.glob('/content/IRDatasetFinal/val/*[0-9].*'):\n",
        "       print(\"test file exists in val directory\", filename)\n",
        "    \n",
        "\n",
        "    #print(\"file train path\", file_train_path)\n",
        "    #print(\"file val path\", file_val_path)\n",
        "\n",
        "    if (os.path.isfile(file_train_path) is True): \n",
        "      print(\"test file exists in train directory\", eachFile)\n",
        "    else:\n",
        "      print(\"No file found in train\", eachFile)  \n",
        "\n",
        "    if (os.path.isfile(file_val_path) is True):\n",
        "      print(\"test file exists in val directory\", eachFile)\n",
        "    else:\n",
        "      print(\"No file found in val\", eachFile)  \n",
        "\n",
        "    #print(os.path.isfile(\"/content/IRDatasetFinal/test/a1570555951_468803.png\"))\n",
        "\n",
        "\n",
        "'''   \n",
        "'''  "
      ],
      "metadata": {
        "id": "Bnh46Rbl755I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls /content/IRDatasetFinal/test/a1603391930_493382.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a0qkLrZlPRr",
        "outputId": "4541665c-7768-4d20-c375-cc94eddf81b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IRDatasetFinal/test/a1603391930_493382.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "these are the files that were not in train or val.total files from 325 that are either in val or train dir are 286\n",
        "a1603391930_493382\n",
        "a1602782592_279944\n",
        "a1635456565_019968\n",
        "a1635456089_002472\n",
        "a1635457245_031288\n",
        "a1600888241_188905\n",
        "a1635461259_005672\n",
        "a1622943208_834271\n",
        "a1635458544_023433\n",
        "a1622942749_109772\n",
        "a1622943039_769827\n",
        "a1635457210_999884\n",
        "a1635457743_9989\n",
        "a1635456786_011603\n",
        "a1604682965_453746\n",
        "a1602782574_324635\n",
        "a1622943519_360246\n",
        "a1603387335_016333\n",
        "a1635461209_007017\n",
        "a1635461219_006688\n",
        "a1635455953_006892\n",
        "a1635452510_014722\n",
        "a1635458124_004488\n",
        "a1635458814_014660\n",
        "a1635459559_024613\n",
        "a1602782555_457181\n",
        "a1635461448_999508\n",
        "a1603392040_224361\n",
        "a1603388439_014541\n",
        "a1635456820_011965\n",
        "a1571166212_314216\n",
        "a1635459169_003060\n",
        "a1635457894_011637\n",
        "a1602782694_288267\n",
        "a1602783133_252807\n",
        "a1635453716_009826\n",
        "a1635453590_013916\n",
        "a1603210859_015065\n",
        "a1622943419_195525\n",
        "'''"
      ],
      "metadata": {
        "id": "xG-rtU9JUDv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Count the number of images in test and testannot again\n",
        "import os \n",
        "APP_FOLDER = '/content/IRDatasetFinal/test'\n",
        "totalFiles = 0\n",
        "totalDir = 0\n",
        "\n",
        "for base, dirs, files in os.walk(APP_FOLDER):\n",
        "    print('Searching in : ',base)\n",
        "    for directories in dirs:\n",
        "        totalDir += 1\n",
        "    for Files in files:\n",
        "        totalFiles += 1\n",
        "   \n",
        "\n",
        "print('Total number of files',totalFiles)\n",
        "print('Total Number of directories',totalDir)\n",
        "print('Total:',(totalDir + totalFiles))\n",
        "'''"
      ],
      "metadata": {
        "id": "81S3JowFl8Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "675_gYSZ1X9M"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D60VHKzY2QWn"
      },
      "source": [
        "IMAGE_SIZE_WIDTH = 640\n",
        "IMAGE_SIZE_HEIGHT = 512\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "NUM_CLASSES = 7\n",
        "#DATA_DIR = '/content/drive/MyDrive/TheIRDatasetMini_backup'\n",
        "DATA_DIR = '/content/IRDatasetFinal'\n",
        "#DATA_DIR = '/content/drive/MyDrive/TheIRDataset'\n",
        "#DATA_DIR = '/content/drive/MyDrive/IR -test'\n",
        "\n",
        "#VAL_DATA_DIR = \"./instance-level_human_parsing/instance-level_human_parsing/Training\"\n",
        "#NUM_TRAIN_IMAGES = 80\n",
        "#NUM_VAL_IMAGES = 10\n",
        "\n",
        "\n",
        "test_images = sorted(glob(os.path.join(DATA_DIR, \"test/*\")))\n",
        "test_masks = sorted(glob(os.path.join(DATA_DIR, \"testannot/*\")))\n",
        "\n",
        "\n",
        "def read_image(image_path, mask=False):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    #print(\"image=\", image)\n",
        "    if mask:\n",
        "        image = tf.image.decode_png(image, channels=0, dtype=tf.uint8)\n",
        "        #print(\"mask 1st read\", image)\n",
        "        #print(\"Max value of mask as per tef.reduce are\", tf.reduce_max(image))\n",
        "        image.set_shape([None, None, 1])\n",
        "        #print(\"mask 2nd read\", image)\n",
        "        image = tf.image.resize(images=image, method= 'nearest', size=[IMAGE_SIZE_HEIGHT, IMAGE_SIZE_WIDTH])\n",
        "        #print(\"mask 3rd read after resize\", image)\n",
        "        #print('final image' ,image)\n",
        "        #print('unique values of tensor' , tf.unique(image))\n",
        "    else:\n",
        "        image = tf.image.decode_png(image, channels=3, dtype=tf.uint8)\n",
        "        #print(\"1st step in read image\", image)\n",
        "        image.set_shape([None, None, 3])\n",
        "        #print(\"2nd step in read image\", image)\n",
        "        image = tf.image.resize(images=image, method= 'bilinear', size=[IMAGE_SIZE_HEIGHT, IMAGE_SIZE_WIDTH])\n",
        "        image = image / 127.5 - 1\n",
        "        #print(\"image looks like\", image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_data(image_list, mask_list):\n",
        "    image = read_image(image_list)\n",
        "    mask = read_image(mask_list, mask=True)\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def data_generator(image_list, mask_list):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-2OJmow2VhG"
      },
      "source": [
        "'''\n",
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp4GSu2r2cIi"
      },
      "source": [
        "'''\n",
        "def DeeplabV3Plus(image_size, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        #weights=\"imagenet\", include_top=False, input_tensor=model_input - removed imagenet weights\n",
        "        weights=None, include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "\n",
        "model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "model.summary()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jv41GSo2fm6"
      },
      "source": [
        "'''\n",
        "#### This is the training cell\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "my_callbacks = [\n",
        "    #tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/Logs/Unet-7classes-finalpapersubmission'),\n",
        "    keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/deeplab-finalpapersubmission\", save_freq = 'epoch')\n",
        "\n",
        "]\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, callbacks = my_callbacks, epochs=25)\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.ylabel(\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.ylabel(\"val_accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "model.save(\"/content/drive/MyDrive/Models/deeplab-finalpapersubmission\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib1YVia5QVAu"
      },
      "source": [
        "## Inference \n",
        "## this is to use the saved model for predictions\n",
        "#reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/Models/deeplab-finalpapersubmission\")\n",
        "#reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/Models/deeplab/deeplab-finalpapersubmission-2020only\")\n",
        "#reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only\")\n",
        "reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnz-wuZq2jV-"
      },
      "source": [
        "import PIL\n",
        "#matplotlib.pyplot.ioff()\n",
        "\n",
        "# Loading the Colormap. Defaulting since i have changed the colors hardcoded in the code\n",
        "'''\n",
        "colormap = loadmat(\n",
        "   \"/content/drive/MyDrive/deeplab/human_colormap.mat\")[\"colormap\"]\n",
        "colormap = colormap * 100\n",
        "colormap = colormap.astype(np.uint8)\n",
        "print(\"shape of colormap\", np.shape(colormap)) - (20,3)\n",
        "print(\"type of colormap\", type(colormap)) - ndarray \n",
        "'''\n",
        "\n",
        "colormap = np.ndarray(shape=(7,3), dtype=int);\n",
        "#colormap = np.zeros(7,3) \n",
        "#0 - sky - dark blue\n",
        "colormap[0,0]=0\n",
        "colormap[0,1]=113\n",
        "colormap[0,2]=188\n",
        "\n",
        "#1 - water - orange\n",
        "colormap[1,0]= 216\n",
        "colormap[1,1]= 82\n",
        "colormap[1,2]= 24\n",
        "\n",
        "#2 - bridge - yellow\n",
        "colormap[2,0]= 236\n",
        "colormap[2,1]= 176\n",
        "colormap[2,2]= 31\n",
        "\n",
        "#3 - obstacle - purple\n",
        "colormap[3,0]= 125\n",
        "colormap[3,1]= 46\n",
        "colormap[3,2]= 141\n",
        "\n",
        "#4 - living obstacle - green\n",
        "colormap[4,0]= 118\n",
        "colormap[4,1]= 171\n",
        "colormap[4,2]= 47\n",
        "\n",
        "#5 - backgnd - brown\n",
        "colormap[5,0]= 161\n",
        "colormap[5,1]= 19\n",
        "colormap[5,2]= 46\n",
        "\n",
        "#6 - self - red\n",
        "colormap[6,0]= 255\n",
        "colormap[6,1]= 0\n",
        "colormap[6,2]= 0\n",
        "\n",
        "def infer(model, image_tensor):\n",
        "    #print(\"image tensor looks like\", image_tensor)\n",
        "    predictions = reconstructed_model.predict(np.expand_dims((image_tensor), axis=0))\n",
        "    #print(\"predictions 1st step\", predictions)\n",
        "    predictions = np.squeeze(predictions)\n",
        "    #print(\"predictions 2nd step after squeeze\", predictions)\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    #print(\"predictions 3rd step after argmax\", predictions)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def decode_segmentation_masks(mask, colormap, n_classes):\n",
        "    r = np.zeros_like(mask).astype(np.uint8)\n",
        "    g = np.zeros_like(mask).astype(np.uint8)\n",
        "    b = np.zeros_like(mask).astype(np.uint8)\n",
        "    \n",
        "    for l in range(0, n_classes):\n",
        "        idx = mask == l\n",
        "        r[idx] = colormap[l, 0]\n",
        "        g[idx] = colormap[l, 1]\n",
        "        b[idx] = colormap[l, 2]\n",
        "    rgb = np.stack([r, g, b], axis=2)\n",
        "    #print(rgb)\n",
        "    return rgb\n",
        "\n",
        "\n",
        "def get_overlay(image, colored_mask):\n",
        "    image = tf.keras.preprocessing.image.array_to_img(image)\n",
        "    image = np.array(image).astype(np.uint8)\n",
        "    overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)\n",
        "    return overlay\n",
        "\n",
        "\n",
        "#def plot_samples_matplotlib(display_list, figsize=(5, 3)):\n",
        "def plot_samples_matplotlib(display_list, filename, index, start, figsize=(5, 3)):\n",
        "    #_, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
        "    \n",
        "    \n",
        "    for i in range(len(display_list)):\n",
        "        if display_list[i].shape[-1] == 3:\n",
        "            #print(\"shape of display list\", np.shape(tf.keras.preprocessing.image.array_to_img(display_list[i])))\n",
        "            axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        else:\n",
        "            #print(\"shape of display list 2\", np.shape(display_list[i]))\n",
        "            axes[i].imshow(display_list[i])\n",
        "    \n",
        "    index_mod = index+start \n",
        "    #Saving the inferred segmented image as a picture \n",
        "    plt.savefig('/content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/picture/' + str(index_mod) +'--runreviseddata-2--' +  filename)\n",
        "    #plt.cla()\n",
        "    #plt.close(fig)\n",
        "    \n",
        "    #Displays the image on screen         \n",
        "    #print (index)\n",
        "    #plt.show()\n",
        "    \n",
        "\n",
        "\n",
        "def plot_predictions(images_list, masks_list, start, colormap, model):\n",
        "    for (index, mask_file) in enumerate(masks_list):\n",
        "      gt_mask_array = ((np.unique(cv2.imread(mask_file,cv2.IMREAD_UNCHANGED))))\n",
        "      gt_mask = (cv2.imread(mask_file,cv2.IMREAD_UNCHANGED))\n",
        "      #print (\"mask file is\", mask_file)\n",
        "      filename = mask_file.split('/')[-1]\n",
        "      #print(filename)\n",
        "      object_living_array = [1]\n",
        "      if((set(object_living_array) & set(gt_mask_array))== set(object_living_array)):\n",
        "            image_tensor = read_image(images_list[index])\n",
        "            #print(\"shape of image tensor\", np.shape(image_tensor))\n",
        "            prediction_mask = infer(image_tensor=image_tensor, model=reconstructed_model)\n",
        "            #print(prediction_mask)\n",
        "\n",
        "            output_Im = PIL.Image.fromarray(prediction_mask.astype(np.uint8))\n",
        "\n",
        "            index_mod = index+start \n",
        "\n",
        "            ##Saving the category ids in an image for programatic IoU check \n",
        "            output_Im.save(('/content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/program/' + str(index_mod) +'--runreviseddata-2--' +  filename))\n",
        "\n",
        "            prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, 7)\n",
        "            overlay = get_overlay(image_tensor, prediction_colormap)\n",
        "            #print(\"shape of prediction mask is\", np.shape(prediction_mask))\n",
        "            #print(\"prediction colormap success\")\n",
        "\n",
        "            #want to get the gt mask displayed as well\n",
        "            #print(\"shape of gt mask is\", np.shape(gt_mask))\n",
        "            gt_colormap = decode_segmentation_masks(gt_mask, colormap, 7)\n",
        "            #print(\"gt colormap successful\")\n",
        "                              \n",
        "            '''\n",
        "            plot_samples_matplotlib(\n",
        "              [image_tensor, overlay, prediction_colormap], filename, index, start, figsize=(18, 14) \n",
        "              )\n",
        "            '''  \n",
        "            \n",
        "            #adding gt mask to the plot                       \n",
        "            plot_samples_matplotlib(\n",
        "              [image_tensor, overlay, prediction_colormap,gt_colormap], filename, index, start, figsize=(18, 14) \n",
        "            )\n",
        "                              "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = 4000\n",
        "end = 4509\n",
        "plot_predictions(test_images[start:end], test_masks [start:end], start, colormap, model=reconstructed_model)"
      ],
      "metadata": {
        "id": "JoIsnSixncf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This was a a trial to run w/o test masks \n",
        "'''\n",
        "def plot_predictions(images_list, start, colormap, model):\n",
        "    for (index, image_file) in enumerate(images_list):\n",
        "      #gt_mask_array = ((np.unique(cv2.imread(mask_file,cv2.IMREAD_UNCHANGED))))\n",
        "      #gt_mask = (cv2.imread(mask_file,cv2.IMREAD_UNCHANGED))\n",
        "      #print (\"mask file is\", mask_file)\n",
        "      filename = image_file.split('/')[-1]\n",
        "      #print(filename)\n",
        "      object_living_array = [1]\n",
        "      #if((set(object_living_array) & set(gt_mask_array))== set(object_living_array)):\n",
        "      image_tensor = read_image(images_list[index])\n",
        "      prediction_mask = infer(image_tensor=image_tensor, model=reconstructed_model)\n",
        "      #print(prediction_mask)\n",
        "\n",
        "      output_Im = PIL.Image.fromarray(prediction_mask.astype(np.uint8))\n",
        "\n",
        "      index_mod = index+start \n",
        "\n",
        "      ##Saving the category ids in an image for programatic IoU check \n",
        "      output_Im.save(('/content/drive/MyDrive/InferenceLarge20192020shuffled/deeplab/program/' + str(index_mod) +'--runall-1--' +  filename))\n",
        "\n",
        "      prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, 7)\n",
        "      overlay = get_overlay(image_tensor, prediction_colormap)\n",
        "      #print(\"shape of prediction mask is\", np.shape(prediction_mask))\n",
        "      #print(\"prediction colormap success\")\n",
        "\n",
        "      #want to get the gt mask displayed as well\n",
        "      #print(\"shape of gt mask is\", np.shape(gt_mask))\n",
        "      #gt_colormap = decode_segmentation_masks(gt_mask, colormap, 7)\n",
        "      #print(\"gt colormap successful\")\n",
        "\n",
        "      \n",
        "      plot_samples_matplotlib(\n",
        "            [image_tensor, overlay, prediction_colormap], filename, index, start, figsize=(18, 14) \n",
        "      )\n",
        "      #adding gt mask to the plot                       )\n",
        "      plot_samples_matplotlib(\n",
        "              [image_tensor, overlay, prediction_colormap], filename, index, start, figsize=(18, 14) \n",
        "                             )\n",
        "'''"
      ],
      "metadata": {
        "id": "SsoaPjImlUd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "start = 0\n",
        "end = 20\n",
        "plot_predictions(test_images[start:end],  start, colormap, model=reconstructed_model)\n",
        "'''"
      ],
      "metadata": {
        "id": "dVNLuxtMmXmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}