{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IR_7classes_Unet_Finalpaper_submission_Inference",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssnirgudkar/Datasetpaper-final/blob/main/IR_7classes_Unet_Finalpaper_submission_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nmjKJ8iztVY"
      },
      "source": [
        "Use this as the final code. - DOES NOT USE ANY PREEXISTING WEIGHTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mr3hxfyDRis",
        "outputId": "50ce7982-4893-4d54-ee0d-752de6e24f8e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "aRF78c43RdG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/test.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/testannot.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "# Zip file with handpicked test images\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/select_test_images.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "# Zip file with masks of handpicked test images\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/select_test_masks.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "# copy the select_test_images and masks in test and testannot respectively \n",
        "!cp /content/IRDatasetFinal/select_test_images/*.png /content/IRDatasetFinal/test\n",
        "!cp /content/IRDatasetFinal/select_test_masks/*.png /content/IRDatasetFinal/testannot"
      ],
      "metadata": {
        "id": "KK-yzVFNDSjr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "APP_FOLDER = '/content/IRDatasetFinal/testannot'\n",
        "totalFiles = 0\n",
        "totalDir = 0\n",
        "\n",
        "for base, dirs, files in os.walk(APP_FOLDER):\n",
        "    print('Searching in : ',base)\n",
        "    for directories in dirs:\n",
        "        totalDir += 1\n",
        "    for Files in files:\n",
        "        totalFiles += 1\n",
        "   \n",
        "\n",
        "print('Total number of files',totalFiles)\n",
        "print('Total Number of directories',totalDir)\n",
        "print('Total:',(totalDir + totalFiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuKFa_k3DZa1",
        "outputId": "4ff623f2-b38f-436c-ed9c-2b8e19993bdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching in :  /content/IRDatasetFinal/testannot\n",
            "Total number of files 3765\n",
            "Total Number of directories 0\n",
            "Total: 3765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now remove images that are not pure (rotated, mirrored etc from the test and testannot folders) \n",
        "# as we do not want to use them for testing \n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "test_dir = \"/content/IRDatasetFinal/test\"\n",
        "test_mask_dir = \"/content/IRDatasetFinal/testannot\"\n",
        "# Move rotated & mirrored files into tmp directory\n",
        "# The format of these files is aXXX_XXX_XX.png and aXXX_XXX_XX_XX.png\n",
        "# Number of underscores is 2 or 3\n",
        "dest_test_dir = \"/content/IRDatasetFinal/test_tmp\"\n",
        "dest_mask_dir = \"/content/IRDatasetFinal/testannot_tmp\"\n",
        "\n",
        "# Move non-augmented files from test directory into a temporary directory\n",
        "if (False == os.path.exists(dest_test_dir)):\n",
        "  os.mkdir(dest_test_dir)\n",
        "if (False == os.path.exists(dest_mask_dir)):\n",
        "  os.mkdir(dest_mask_dir)\n",
        "\n",
        "\n",
        "for eachFile in os.listdir(test_dir):\n",
        "  numUnderscores = eachFile.count('_')\n",
        "  if (numUnderscores > 1):\n",
        "    # File names in image & mask directories are identical so move both files in one shot!\n",
        "    shutil.move(os.path.join(test_dir, eachFile), os.path.join(dest_test_dir))\n",
        "    shutil.move(os.path.join(test_mask_dir, eachFile), os.path.join(dest_mask_dir))\n",
        "    \n",
        "'''\n",
        "    for eachFile in os.listdir(test_mask_dir):\n",
        "      numUnderscores = eachFile.count('_')\n",
        "      if (numUnderscores > 1):\n",
        "        # File names in image & mask directories are identical so move both files in one shot!\n",
        "        shutil.move(os.path.join(test_mask_dir, eachFile), os.path.join(dest_mask_dir))\n",
        "'''\n"
      ],
      "metadata": {
        "id": "aCiolPJKNBAl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5ba2b256-3b68-469d-e905-e4fce072c04e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n    for eachFile in os.listdir(test_mask_dir):\\n      numUnderscores = eachFile.count('_')\\n      if (numUnderscores > 1):\\n        # File names in image & mask directories are identical so move both files in one shot!\\n        shutil.move(os.path.join(test_mask_dir, eachFile), os.path.join(dest_mask_dir))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of images in test and testannot again\n",
        "import os \n",
        "APP_FOLDER = '/content/IRDatasetFinal/test'\n",
        "totalFiles = 0\n",
        "totalDir = 0\n",
        "\n",
        "for base, dirs, files in os.walk(APP_FOLDER):\n",
        "    print('Searching in : ',base)\n",
        "    for directories in dirs:\n",
        "        totalDir += 1\n",
        "    for Files in files:\n",
        "        totalFiles += 1\n",
        "   \n",
        "\n",
        "print('Total number of files',totalFiles)\n",
        "print('Total Number of directories',totalDir)\n",
        "print('Total:',(totalDir + totalFiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYrN6Yk8U8-V",
        "outputId": "26f2c2aa-642b-4d51-f843-17e739d6f99d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching in :  /content/IRDatasetFinal/test\n",
            "Total number of files 325\n",
            "Total Number of directories 0\n",
            "Total: 325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "754aS1YJgOVn"
      },
      "source": [
        "# Image segmentation with a U-Net-like architecture\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2019/03/20<br>\n",
        "**Last modified:** 2020/04/20<br>\n",
        "**Description:** Image segmentation model trained from scratch on the Oxford Pets dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jUdvZcqUxIb"
      },
      "source": [
        "##Inference corresponding to run#7 of training - No preloaded weights - actual size images + mirror + rotate . GPU (Standard RAM)\n",
        "train - 26081  val - 7452  test - 3726 \n",
        ", epochs = 100\n",
        "training time - 2 days, testing -  min  \n",
        "Model - /Models/Unet-7classes-finalpapersubmission2\n",
        "file names prefix - run11 \n",
        "Loss - 0.0341\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XufPVSlGtx0e",
        "outputId": "5eebc9b9-72b6-4954-f246-92241651609e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"keras version is\", tf.keras.__version__)\n",
        "print (\"tf version is\", tf.__version__) \n",
        "!python --version"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras version is 2.7.0\n",
            "tf version is 2.7.0\n",
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQgZp6JWgOVp"
      },
      "source": [
        "## Prepare paths of input images and target segmentation masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qGXBC0LgOVp"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "input_dir_test = \"/content/IRDatasetFinal/test\" # directory containing 2570 IR input images\n",
        "target_dir_test = \"/content/IRDatasetFinal/testannot\" # directory containing 2570 segmented IR images\n",
        "\n",
        "img_size = (512, 640) #it's height and width. it's a 1/2 sized image from the original image from segment.ai\n",
        "#img_size = (512, 640) #it's height and width. This is the original image from segment.ai\n",
        "#img_size_width_ht = (320,256)\n",
        "img_size_width_ht = (640,512)\n",
        "\n",
        "num_classes = 7\n",
        "batch_size = 10\n",
        "test_batch_size = 1\n",
        " \n",
        "\n",
        "# check for distinct label values in all masked files \n",
        "def getFullyQualifiedImagePaths(image_dir):\n",
        "  return sorted([ os.path.join(image_dir, fname)\n",
        "                  for fname in os.listdir(image_dir)\n",
        "                  if fname.endswith(\".png\")\n",
        "                ])\n",
        " \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5SOaM9JvIao",
        "outputId": "a337939e-07b3-4d3e-bea5-90692133cf51"
      },
      "source": [
        "# Inference \n",
        "#prints how many files are in the test batch\n",
        "input_test_paths = getFullyQualifiedImagePaths(input_dir_test)\n",
        "target_test_paths = getFullyQualifiedImagePaths(target_dir_test)\n",
        "\n",
        "#prints how many files are in the batch\n",
        "print(\"Number of test images:\", len(input_test_paths))\n",
        "print(\"Number of test masks:\", len(target_test_paths))\n",
        "\n",
        "#pattern of the test images and masks \n",
        "for input_path, target_path in zip(input_test_paths[:5], target_test_paths[:5]):\n",
        "    print(input_path, \"|\", target_path)\n",
        "\n",
        "#!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test images: 325\n",
            "Number of test masks: 325\n",
            "/content/IRDatasetFinal/test/a1570555951_468803.png | /content/IRDatasetFinal/testannot/a1570555951_468803.png\n",
            "/content/IRDatasetFinal/test/a1570556157_235576.png | /content/IRDatasetFinal/testannot/a1570556157_235576.png\n",
            "/content/IRDatasetFinal/test/a1570556226_469019.png | /content/IRDatasetFinal/testannot/a1570556226_469019.png\n",
            "/content/IRDatasetFinal/test/a1570556228_902274.png | /content/IRDatasetFinal/testannot/a1570556228_902274.png\n",
            "/content/IRDatasetFinal/test/a1570556229_202275.png | /content/IRDatasetFinal/testannot/a1570556229_202275.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n26N4oURgOVq"
      },
      "source": [
        "## Prepare `Sequence` class to load & vectorize batches of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvauKhqOgOVr"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "\n",
        "class OxfordPets(keras.utils.Sequence):\n",
        "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size)\n",
        "            x[j] = img\n",
        "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
        "            #in case we want to see if masked image have the right values\n",
        "            #print(tensorflow.keras.preprocessing.image.img_to_array(img))\n",
        "            y[j] = np.expand_dims(img, 2)\n",
        "            # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2: \n",
        "            #if classes are 3, keras expects masked values to be 0,1,2 only. Cannot take 1,3,5. It checks numerically not just the number of masked values\n",
        "            #y[j] += 1 \n",
        "        return x, y\n",
        "#!nvidia-smi\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nJLhugZvqTP"
      },
      "source": [
        "# Inference \n",
        "import random\n",
        "# Instantiate data Sequences for each split\n",
        "\n",
        "test_gen = OxfordPets(test_batch_size, img_size, input_test_paths, target_test_paths)\n",
        "#!nvidia-smi"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach\n",
        "1. load a model \n",
        "2. in a for loop\n",
        "3. OxfordPets give 2 images at a time\n",
        "4. run prediction\n",
        "5. visualize and save"
      ],
      "metadata": {
        "id": "zjPPcQqYGV5U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9gYCGN4gOVt"
      },
      "source": [
        "## Visualize predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!nvidia-smi\n",
        "\n"
      ],
      "metadata": {
        "id": "UOcb3bzQdBnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model \n",
        "#reconstructed_model1 = keras.models.load_model(\"/content/drive/MyDrive/Models/Unet-7classes-finalpapersubmission2\") # model with 2019 and 2020 data for 100 epochs\n",
        "#reconstructed_model1 = keras.models.load_model(\"/content/drive/MyDrive/Models/unet/Unet-7classes-finalpapersubmission_2020only\") # model with 2020 only images for 50 epochs\n",
        "reconstructed_model1 = keras.models.load_model(\"/content/drive/MyDrive/Models/unet/Unet-7classes-finalpapersubmission_2019&2020_shuffled\") # model with all imaged and shuffled\n",
        "\n"
      ],
      "metadata": {
        "id": "-syDRT_NHCP1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfDabGp9atzh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "769b5f36-9e7a-4917-9b49-855dff4f736e"
      },
      "source": [
        "#### Prediction\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import PIL\n",
        "from PIL import ImageOps\n",
        "\n",
        "def display_mask(i,file_num_dir,imagefilepathtokens):\n",
        "    \"\"\"Quick utility to display a model's prediction. we need color masked images, so displaying both color and black and white\"\"\"\n",
        "    \n",
        "    #0 - sky(dark.blue). \n",
        "    #1 - water(light.blue).   \n",
        "    #2 - bridge(yellow).   \n",
        "    #3 - obstacle(purple).  \n",
        "    #4- living ob(green).  \n",
        "    #5- backgnd (orange). \n",
        "    #6 - self(pink)\n",
        "    # Colors are same as segments.ai scheme\n",
        "    label_colours = [(0,113,188), (216,82,24), (236,176,31), (125, 46, 141), (118, 171, 47), (161, 19, 46), (255,0,0)]  \n",
        "    \n",
        "    \n",
        "    mask = np.argmax(test_preds1[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    #print(\"mask shape = \", np.shape(mask))\n",
        "    #print(\"mask length = \", len(mask[i, 0]))\n",
        "    #print(\"mask length = \", len(mask[i]))\n",
        "    #print(\"Unique pixel values = \", np.unique(mask))\n",
        "    #print(\"Type of mask = \", type(mask))\n",
        "    \n",
        "   \n",
        "    #img1 = PIL.Image.new('RGB', (640, 512))\n",
        "    img1 = PIL.Image.new('RGB', img_size_width_ht)\n",
        "    #print (\"image size\", img_size_width_ht)\n",
        "    pixels = img1.load()\n",
        "    #print(type(pixels))\n",
        "    #print(pixels[0,0])\n",
        "    for j_, j in enumerate(mask[:, :, 0]):\n",
        "        #print (j_, j)\n",
        "        for k_, k in enumerate(j):\n",
        "             #print(k_, k)\n",
        "             if k < num_classes:\n",
        "                pixels[k_,j_] = label_colours[k]\n",
        "    output = np.array(img1)\n",
        "\n",
        "    outputpicturePath = '/content/drive/MyDrive/InferenceLarge20192020shuffled/unet/picture' + '/' + str(file_num_dir) + '--runall-2--' + imagefilepathtokens[-1]     \n",
        "    \n",
        "    #print(\"this is the colored inferred image\")\n",
        "    #display(img1)\n",
        "\n",
        "    ##Saving the category ids in an image for programatic IoU check \n",
        "    img1.save(outputpicturePath)\n",
        "\n",
        "    '''\n",
        "    print(\"this is the gray inferred image\")\n",
        "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "    '''\n",
        "    return mask\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "test_input_dir1 = \"/content/IRDatasetFinal/test\"  \n",
        "test_target_input_dir1 = \"/content/IRDatasetFinal/testannot\"  \n",
        "test_input_img_paths1 = getFullyQualifiedImagePaths(test_input_dir1)\n",
        "test_target_img_paths1 = getFullyQualifiedImagePaths(test_target_input_dir1)\n",
        "no_of_test_img = len(test_input_img_paths1)\n",
        "print(\"Num test images = {0}\".format(no_of_test_img))\n",
        "\n",
        "prev = 0\n",
        "for i in range(1, no_of_test_img+1, 2):\n",
        "#for i in range(11, 20+1, 2):\n",
        "    #print(\"prev={0},i={1}\".format(prev,i))\n",
        "    test_gen1 = OxfordPets(test_batch_size, img_size, test_input_img_paths1[prev:i+1], test_target_img_paths1[prev:i+1])\n",
        "    print(\"iteration running is\", i)\n",
        "    #print(\"image_path\", test_input_img_paths1[i])\n",
        "    #!nvidia-smi\n",
        "    tf.compat.v1.GPUOptions(allow_growth=True)\n",
        "    test_preds1 = reconstructed_model1.predict(test_gen1)\n",
        "    #print(\"Size of test_preds1 = {0}\".format(len(test_preds1)))\n",
        "    #!nvidia-smi\n",
        "    #free memory / restart runtime \n",
        "\n",
        "    # Inference \n",
        "    ## Now visualize predictions for a specific image. Change the value of i\n",
        "\n",
        "    for jj in range(0, 2):\n",
        "        # check if ground-truth target mask as any object - class id - 3\n",
        "        image_gt = tf.keras.preprocessing.image.load_img(test_target_img_paths1[jj])\n",
        "        input_arr = tf.keras.preprocessing.image.img_to_array(image_gt)\n",
        "        gt_mask_array = np.unique(input_arr) \n",
        "        object_living_array = [1] # we need all 300+ images. hence putting here 1 instead of 3,4\n",
        "        #print(gt_mask_array)\n",
        "        #intersect_array_object = np.intersect1d(gt_mask_array, object_array) \n",
        "        #intersect_array_living = np.intersect1d(gt_mask_array, living_array) \n",
        "        if((set(object_living_array) & set(gt_mask_array))== set(object_living_array)):\n",
        "            #print (\"intersect output 2\", gt_mask_array )\n",
        "            #print(gt_mask_array)\n",
        "            #display the raw input image \n",
        "\n",
        "            file_num_dir = prev+jj #this denotes the sequence of the image in the test dir\n",
        "            #print(\"this is the raw image\")\n",
        "            #display(Image(filename=test_input_img_paths1[file_num_dir]))\n",
        "          \n",
        "            #display the ground truth masked image \n",
        "            img = PIL.ImageOps.autocontrast(load_img(test_target_img_paths1[file_num_dir]))\n",
        "            #print(\"this is the ground truth mask\")\n",
        "            #display(img)\n",
        "          \n",
        "            #set file names for storing the prediction \n",
        "            imagefilepathtokens = test_input_img_paths1[file_num_dir].split('/')\n",
        "            #print(\"tokens = \", imagefilepathtokens)\n",
        "\n",
        "            outputFilePath = '/content/drive/MyDrive/InferenceLarge20192020shuffled/unet/program' + '/' + str(file_num_dir) + '--runall-2--' + imagefilepathtokens[-1] \n",
        "            #print(\"output file name = \", outputFilePath)\n",
        "\n",
        "            #invoke the prediction function \n",
        "            output_mask = display_mask(jj,file_num_dir,imagefilepathtokens)  # Note that the model only sees inputs at 150x150.\n",
        "            output_mask = np.squeeze(output_mask, axis=2)\n",
        "            #result = np.where(output_mask==0)\n",
        "            #print(\"indices where output_mask has 0 value = \", result)\n",
        "            output_Im = PIL.Image.fromarray(output_mask.astype(np.uint8))\n",
        "\n",
        "            ##Saving the category ids in an image for programatic IoU check \n",
        "            output_Im.save(outputFilePath)      \n",
        "    prev = i+1      \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num test images = 325\n",
            "iteration running is 1\n",
            "iteration running is 3\n",
            "iteration running is 5\n",
            "iteration running is 7\n",
            "iteration running is 9\n",
            "iteration running is 11\n",
            "iteration running is 13\n",
            "iteration running is 15\n",
            "iteration running is 17\n",
            "iteration running is 19\n",
            "iteration running is 21\n",
            "iteration running is 23\n",
            "iteration running is 25\n",
            "iteration running is 27\n",
            "iteration running is 29\n",
            "iteration running is 31\n",
            "iteration running is 33\n",
            "iteration running is 35\n",
            "iteration running is 37\n",
            "iteration running is 39\n",
            "iteration running is 41\n",
            "iteration running is 43\n",
            "iteration running is 45\n",
            "iteration running is 47\n",
            "iteration running is 49\n",
            "iteration running is 51\n",
            "iteration running is 53\n",
            "iteration running is 55\n",
            "iteration running is 57\n",
            "iteration running is 59\n",
            "iteration running is 61\n",
            "iteration running is 63\n",
            "iteration running is 65\n",
            "iteration running is 67\n",
            "iteration running is 69\n",
            "iteration running is 71\n",
            "iteration running is 73\n",
            "iteration running is 75\n",
            "iteration running is 77\n",
            "iteration running is 79\n",
            "iteration running is 81\n",
            "iteration running is 83\n",
            "iteration running is 85\n",
            "iteration running is 87\n",
            "iteration running is 89\n",
            "iteration running is 91\n",
            "iteration running is 93\n",
            "iteration running is 95\n",
            "iteration running is 97\n",
            "iteration running is 99\n",
            "iteration running is 101\n",
            "iteration running is 103\n",
            "iteration running is 105\n",
            "iteration running is 107\n",
            "iteration running is 109\n",
            "iteration running is 111\n",
            "iteration running is 113\n",
            "iteration running is 115\n",
            "iteration running is 117\n",
            "iteration running is 119\n",
            "iteration running is 121\n",
            "iteration running is 123\n",
            "iteration running is 125\n",
            "iteration running is 127\n",
            "iteration running is 129\n",
            "iteration running is 131\n",
            "iteration running is 133\n",
            "iteration running is 135\n",
            "iteration running is 137\n",
            "iteration running is 139\n",
            "iteration running is 141\n",
            "iteration running is 143\n",
            "iteration running is 145\n",
            "iteration running is 147\n",
            "iteration running is 149\n",
            "iteration running is 151\n",
            "iteration running is 153\n",
            "iteration running is 155\n",
            "iteration running is 157\n",
            "iteration running is 159\n",
            "iteration running is 161\n",
            "iteration running is 163\n",
            "iteration running is 165\n",
            "iteration running is 167\n",
            "iteration running is 169\n",
            "iteration running is 171\n",
            "iteration running is 173\n",
            "iteration running is 175\n",
            "iteration running is 177\n",
            "iteration running is 179\n",
            "iteration running is 181\n",
            "iteration running is 183\n",
            "iteration running is 185\n",
            "iteration running is 187\n",
            "iteration running is 189\n",
            "iteration running is 191\n",
            "iteration running is 193\n",
            "iteration running is 195\n",
            "iteration running is 197\n",
            "iteration running is 199\n",
            "iteration running is 201\n",
            "iteration running is 203\n",
            "iteration running is 205\n",
            "iteration running is 207\n",
            "iteration running is 209\n",
            "iteration running is 211\n",
            "iteration running is 213\n",
            "iteration running is 215\n",
            "iteration running is 217\n",
            "iteration running is 219\n",
            "iteration running is 221\n",
            "iteration running is 223\n",
            "iteration running is 225\n",
            "iteration running is 227\n",
            "iteration running is 229\n",
            "iteration running is 231\n",
            "iteration running is 233\n",
            "iteration running is 235\n",
            "iteration running is 237\n",
            "iteration running is 239\n",
            "iteration running is 241\n",
            "iteration running is 243\n",
            "iteration running is 245\n",
            "iteration running is 247\n",
            "iteration running is 249\n",
            "iteration running is 251\n",
            "iteration running is 253\n",
            "iteration running is 255\n",
            "iteration running is 257\n",
            "iteration running is 259\n",
            "iteration running is 261\n",
            "iteration running is 263\n",
            "iteration running is 265\n",
            "iteration running is 267\n",
            "iteration running is 269\n",
            "iteration running is 271\n",
            "iteration running is 273\n",
            "iteration running is 275\n",
            "iteration running is 277\n",
            "iteration running is 279\n",
            "iteration running is 281\n",
            "iteration running is 283\n",
            "iteration running is 285\n",
            "iteration running is 287\n",
            "iteration running is 289\n",
            "iteration running is 291\n",
            "iteration running is 293\n",
            "iteration running is 295\n",
            "iteration running is 297\n",
            "iteration running is 299\n",
            "iteration running is 301\n",
            "iteration running is 303\n",
            "iteration running is 305\n",
            "iteration running is 307\n",
            "iteration running is 309\n",
            "iteration running is 311\n",
            "iteration running is 313\n",
            "iteration running is 315\n",
            "iteration running is 317\n",
            "iteration running is 319\n",
            "iteration running is 321\n",
            "iteration running is 323\n",
            "iteration running is 325\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-db773549f2e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m#display the ground truth masked image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocontrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target_img_paths1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_num_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;31m#print(\"this is the ground truth mask\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m#display(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}