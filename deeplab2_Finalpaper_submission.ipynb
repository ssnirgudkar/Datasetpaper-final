{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplab2-Finalpaper_submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7MP4aSk7C0McXXzJajg/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssnirgudkar/Datasetpaper-final/blob/main/deeplab2_Finalpaper_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW3lSbsBxFzp"
      },
      "source": [
        "## Use this version as the most final\n",
        "\n",
        "creates model folder automatically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GKo9sXGKeri"
      },
      "source": [
        "to do - \n",
        "1. Batch size should be 10 (identical with UNet, PSPNet) - This batch size gives OOM. 7 is the max we can go with regular RAM\n",
        "2. Image size 512*512 : Is this really needed? We are not using imagenet weights anyway. - Updted to use the actual \n",
        "3. Shuffle the training and validation images. Use the code which was shared earlier. I think this will be beneficial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoAs-oCSzGI6"
      },
      "source": [
        "## we have to keep batchsize = 2 or more. It does not run with batch size 1. Image will be resized to 512*512\n",
        "## mask datatype is uint8. segments.ai semantic masks are uint8 and instance masks are uint16. We need to be careful about which type of masks are getting processed else it reads masks as 0. \n",
        "##the resize was changed to nearest. but we can check if thats needed. bilinear is default. So we can try to keep it as bilinera and that shld also work. With this run, objects were not coming up well. objects and background was getting mixed\n",
        "\n",
        "Run2 11/11 - Uncommented the 127.5-1 code. so now both image and masks are float 32. also changed the nearest back to bilnear. changed the batch size from 10 to 4. running with 50 epochs to see how it works.\n",
        "\n",
        "Train images - \n",
        "Val images - \n",
        "Test images \n",
        "Epochs - 500 \n",
        "Train time -\n",
        "\n",
        "##Run3 - \n",
        "Train images - 3438\n",
        "Val images - 982\n",
        "Test images - 492\n",
        "Epochs - 50 \n",
        "Train time - 3 hrs 49 min\n",
        "Test time - \n",
        "Any preloaded weights - NO. Imagenet weights are not used\n",
        "The masks are uint8. the code had it as uint16. Hence we were getting pixel values of 257. fixed that\n",
        "Model - deeplab-finalpapersubmission_V1\n",
        "\n",
        "##Run4 - \n",
        "Train images - 26081\n",
        "Val images - 7452\n",
        "Test images - 3726\n",
        "Epochs - 25(will break into 4 parts as this is a big dataset.  \n",
        "Train time - 10 hrs 40 min\n",
        "Test time - \n",
        "Any preloaded weights - NO. Imagenet weights are not used\n",
        "Model - deeplab-finalpapersubmission (the next ones will be submission2,3 and 4)\n",
        "infernce folder - IRDatasetFinal-Inferences\n",
        "loss: 0.0623 - accuracy: 0.9790 \n",
        "\n",
        "##Run5 - 2020 & 2021\n",
        "loss: 0.0361 - accuracy: 0.9873 - val_loss: 3.3841 - val_accuracy: 0.7209\n",
        "epochs - 50 \n",
        "ran with 2020 and 2021 dataset only \n",
        "Model - deeplab folder - deeplab-finalpapersubmission-2020only (there's another with 2020-only. need to check)\n",
        "training time - 9 hrs, 27 min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaETn9Z21S9y"
      },
      "source": [
        "# https://keras.io/examples/vision/deeplabv3_plus/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl9XF-Fty5RZ",
        "outputId": "f6e8b802-db23-4c15-cfaf-41f80ad8a07d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/train.zip\", \"r\")\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/train.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/trainannot.zip\", \"r\")\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/trainannot.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/val.zip\", \"r\")\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/val.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/valannot.zip\", \"r\")\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/valannot.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "'''\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/test.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/testannot.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "'''"
      ],
      "metadata": {
        "id": "ClQ6pwk4y6Cv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d582f2cc-8c3a-42ee-aa00-0a828cf5a045"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nzip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/test.zip\", \"r\")\\nzip_ref.extractall(\"/content/IRDatasetFinal\")\\nzip_ref.close()\\n\\nzip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/testannot.zip\", \"r\")\\nzip_ref.extractall(\"/content/IRDatasetFinal\")\\nzip_ref.close()\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "APP_FOLDER = '/content/IRDatasetFinal/train'\n",
        "totalFiles = 0\n",
        "totalDir = 0\n",
        "\n",
        "for base, dirs, files in os.walk(APP_FOLDER):\n",
        "    print('Searching in : ',base)\n",
        "    for directories in dirs:\n",
        "        totalDir += 1\n",
        "    for Files in files:\n",
        "        totalFiles += 1\n",
        "   \n",
        "\n",
        "print('Total number of files',totalFiles)\n",
        "print('Total Number of directories',totalDir)\n",
        "print('Total:',(totalDir + totalFiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LrEwKPVy545",
        "outputId": "0a1b9551-fd33-4cbb-8a20-618a5ef15ca4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching in :  /content/IRDatasetFinal/train\n",
            "Total number of files 26081\n",
            "Total Number of directories 0\n",
            "Total: 26081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "675_gYSZ1X9M"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83c9SFcwp5dM"
      },
      "source": [
        "Downloading the data We will use the Crowd Instance-level Human Parsing Dataset for training our model. The Crowd Instance-level Human Parsing (CIHP) dataset has 38,280 diverse human images. Each image in CIHP is labeled with pixel-wise annotations for 20 categories, as well as instance-level identification. This dataset can be used for the \"human part segmentation\" task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4GnbNOS1gOo"
      },
      "source": [
        "#!gdown https://drive.google.com/uc?id=1B9A9UCJYMwTL4oBEo4RZfbMZMaZhKJaz\n",
        "#!unzip -q instance-level-human-parsing.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGYmazAh-FGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49cd14d6-8d14-4601-920a-450cb66f6c23"
      },
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "# to copy files from google drive to colab memory\n",
        "#%cp -av /content/drive/MyDrive/TheIRDatasetMini/ TheIRDatasetMini\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D60VHKzY2QWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48e5c51-0a56-4ce3-d3ec-47fc1b52fa7b"
      },
      "source": [
        "IMAGE_SIZE_WIDTH = 640\n",
        "IMAGE_SIZE_HEIGHT = 512\n",
        "BATCH_SIZE = 7\n",
        "NUM_CLASSES = 7\n",
        "#DATA_DIR = '/content/drive/MyDrive/TheIRDatasetMini_backup'\n",
        "DATA_DIR = '/content/IRDatasetFinal'\n",
        "#DATA_DIR = '/content/drive/MyDrive/TheIRDataset'\n",
        "#DATA_DIR = '/content/drive/MyDrive/IR -test'\n",
        "\n",
        "#VAL_DATA_DIR = \"./instance-level_human_parsing/instance-level_human_parsing/Training\"\n",
        "#NUM_TRAIN_IMAGES = 80\n",
        "#NUM_VAL_IMAGES = 10\n",
        "\n",
        "'''\n",
        "train_images = sorted(glob(os.path.join(DATA_DIR, \"train/*\")))[:NUM_TRAIN_IMAGES]\n",
        "train_masks = sorted(glob(os.path.join(DATA_DIR, \"trainannot/*\")))[:NUM_TRAIN_IMAGES]\n",
        "val_images = sorted(glob(os.path.join(DATA_DIR, \"train/*\")))[\n",
        "    NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES\n",
        "]\n",
        "val_masks = sorted(glob(os.path.join(DATA_DIR, \"trainannot/*\")))[\n",
        "    NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES\n",
        "]\n",
        "'''\n",
        "train_images = sorted(glob(os.path.join(DATA_DIR, \"train/*\"))) \n",
        "train_masks = sorted(glob(os.path.join(DATA_DIR, \"trainannot/*\"))) \n",
        "indices_train = random.sample(range(len(train_images)), len(train_images))\n",
        "train_images = list(map(train_images.__getitem__, indices_train))\n",
        "train_masks = list(map(train_masks.__getitem__, indices_train))\n",
        "print(\"type of train_images = \", type(train_images))\n",
        "\n",
        "val_images = sorted(glob(os.path.join(DATA_DIR, \"val/*\")))\n",
        "val_masks = sorted(glob(os.path.join(DATA_DIR, \"valannot/*\")))\n",
        "indices_val = random.sample(range(len(val_images)), len(val_images))\n",
        "val_images = list(map(val_images.__getitem__, indices_val))\n",
        "val_masks = list(map(val_masks.__getitem__, indices_val))\n",
        "\n",
        "#test_images = sorted(glob(os.path.join(DATA_DIR, \"test/*\")))\n",
        "#test_masks = sorted(glob(os.path.join(DATA_DIR, \"testannot/*\")))\n",
        "\n",
        "\n",
        "def read_image(image_path, mask=False):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    print(\"image=\", image)\n",
        "    if mask:\n",
        "        image = tf.image.decode_png(image, channels=0, dtype=tf.uint8)\n",
        "        #print(\"mask 1st read\", image)\n",
        "        #print(\"Max value of mask as per tef.reduce are\", tf.reduce_max(image))\n",
        "        image.set_shape([None, None, 1])\n",
        "        #image = tf.cast(image, dtype=tf.float32)\n",
        "        #print(\"mask 2nd read\", image)\n",
        "        image = tf.image.resize(images=image, method= 'nearest', size=[IMAGE_SIZE_WIDTH, IMAGE_SIZE_HEIGHT])\n",
        "        #print(\"mask 3rd read after resize\", image)\n",
        "        #print('final image' ,image)\n",
        "        #print('unique values of tensor' , tf.unique(image))\n",
        "    else:\n",
        "        image = tf.image.decode_png(image, channels=3, dtype=tf.uint8)\n",
        "        #print(\"1st step in read image\", image)\n",
        "        image.set_shape([None, None, 3])\n",
        "        image = tf.cast(image, dtype=tf.float32)\n",
        "        #print(\"2nd step in read image\", image)\n",
        "        image = tf.image.resize(images=image, method= 'bilinear', size=[IMAGE_SIZE_WIDTH, IMAGE_SIZE_HEIGHT])\n",
        "        image = image / 127.5 - 1\n",
        "        #print(\"image looks like\", image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_data(image_list, mask_list):\n",
        "    image = read_image(image_list)\n",
        "    mask = read_image(mask_list, mask=True)\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def data_generator(image_list, mask_list):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_dataset = data_generator(train_images, train_masks)\n",
        "val_dataset = data_generator(val_images, val_masks)\n",
        "\n",
        "read_image(train_masks[20], mask=True)\n",
        "\n",
        "#print ((np.unique(cv2.imread(train_masks[1],cv2.IMREAD_UNCHANGED))))\n",
        "\n",
        "\n",
        "#print(\"Train Dataset:\", train_dataset)\n",
        "#print(\"Val Dataset:\", val_dataset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of train_images =  <class 'list'>\n",
            "image= Tensor(\"ReadFile:0\", shape=(), dtype=string)\n",
            "image= Tensor(\"ReadFile_1:0\", shape=(), dtype=string)\n",
            "image= Tensor(\"ReadFile:0\", shape=(), dtype=string)\n",
            "image= Tensor(\"ReadFile_1:0\", shape=(), dtype=string)\n",
            "image= tf.Tensor(b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\x80\\x00\\x00\\x02\\x00\\x08\\x00\\x00\\x00\\x007\\x16\\x82'\\x00\\x00\\x07\\xeeIDATx\\x9c\\xed\\xdc\\xdbV\\xe2H\\x00@\\xd1\\xd06\\xff\\xff\\xc1\\xae^\\xce\\xc3h7B\\x12\\x02\\x02\\xa7\\xc4\\xbd_T\\xc2\\xa5H\\x0eE\\xc2\\xc5i\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf8Q\\xf6\\xf5\\x00\\x18\\xda\\xee\\xbeW\\xff\\x9e\\xdf\\xeb}o\\x85\\xef\\xeb\\xba\\x00\\xf7\\xd3\\xb4\\xa1\\xaa\\xc3\\xc9O\\x82\\xcc\\xba<\\xc0\\x7fY\\xadGu\\xf4\\xdc\\xab@\\xe6\\xfc\\xba\\xf4\\x02[\\xf7\\xe9\\x8e\\xcfg_\\x909\\x97\\x06\\xb8_\\xf8\\xfd\\xb2K\\xc2\\xbb\\x0b\\x03\\xdc\\\\\\xd1\\xcc\\x19\\xf7\\x12\\xe4\\xc4\\xc5O\\xc1\\x87\\x96\\x8b\\xd2\\x1a\\xdb\\\\\\x16\\xa0\\xae\\xb8\\xb1/\\xcd\\x80\\xf0U\\x17\\x05x2\\x01.\\xcd\\x88fJ62\\x03\\x92\\xfa\\xfd\\xf7\\xb7\\x8fYk\\xf9\\x15\\xe3\\xb9#[\\xaf/\\xf3%\\x7f\\xdf\\t9\\xae\\xeb\\xb4\\xac\\xf9\\xe7\\xd5\\xd9\\x02\\x17\\x9e\\x82\\xd5\\xca\\xb1\\xf7\\x19\\xf0\\xb4\\x98\\xfd3\\xe7rpw\\x9f\\xf8^~\\x0b\\xbf\\xa7ii\\xc2:J\\xf0y\\x0e,\\x9e\\xe7\\x9e<\\x81_\\xd3\\xca\\x06\\xb1\\xa5\\xb8\\xb7_\\xab\\x99\\x1d\\xbc{v\\x83W\\\\\\x06y\\xb6\\xf3\\xb0\\x1a\\xc9\\xef3\\xcb?\\x0es\\x9fg\\xab\\xcd\\xbe\\x989\\xc8c\\xe3\\x07\\xda\\x9d-\\xebu\\x9aV\\xfb\\xdb~\\x18\\x9co\\xe5\\xe5{\\x91\\x0f\\xed\\xc7:7\\x03>\\xd1\\xe1\\xf0\\xf3L\\xe2\\xcfd\\xcb;!\\xfb\\xa7\\xd8vk\\xf7\\xe1I\\x1eb\\xdf\\xd1\\xf9\\x19p:3w\\xec_\\x9ff\\x8e\\x1c\\xdf~\\x88\\x07\\xcbb\\x0f\\xaf\\xd3\\xc5\\xcf\\x98\\xe7\\xf7\\x01\\xb79\\xba\\xd1\\xf1\\xf6\\x01W\\xef\\xe7\\x00\\x1bu\\x8b\\xff\\xefC<\\xd8-\\xc1\\\\0\\xc4[\\x05xp\\xab\\xab\\x8f\\x8f\\xcc\\xfa\\xfd\\x1c\\xb0\\xc0\\xd3o\\x1e\\x9e\\x7f\\xb7\\xfe\\x9eC\\xb9\\xcc\\xe61\\xde0\\xc0iz\\x1dx+\\x0f<\\xb4Y\\xa7\\xb5-|\\x1d\\xf1\\xce_\\xbd\\xbe\\xba\\x8f\\x8d\\x03\\xda\\xb4\\x0f\\xb8\\xd53\\x1c\\xab\\x0cb\\xff\\xe9\\x97\\xd7ii\\xe5\\x9e\\x9e\\xef\\x0ec\\xb8\\xee\\xd2\\xdb\\x06s\\xd3\\x19\\xf0\\x9cr\\x9e\\xf9^3\\xe0\\xc9h??\\xb9\\xccM\\x8b3\\x0bo:\\x82\\xcbm\\x1a\\xc8Mg@nd\\xee\\xc3I\\xeb\\xcb\\x8f\\x17~\\xb5\\xc2\\x87\\xcdK\\x0f\\r\\xd0\\xc7W\\xa7i\\xfe\\xe8b\\xb4\\x15s\\x93\\xfe\\x167\\xf7\\xe1\\xb5?v\\x06\\xec\\n\\x1ce\\xf7t\\x7f\\xf4\\xf3\\xef\\x9f\\xafs'G\\xee;\\x8a\\xcf\\xd7\\xee;!\\xa4\\xec\\x03N\\xd3\\xc3\\x8eA\\xd6f\\x961\\xe6\\xbei\\xba\\xe5H\\xe6\\x9e\\xf0\\x8e\\xaf\\xfd\\xc1\\x01\\xfe\\xe0\\xbd\\xc0q\\n[s\\xefQ\\x9e\\\\\\xff\\xa3g\\xc0;\\xbc\\\\\\xb5\\xf9fS\\xfd\\x086\\xb8\\xf5 7\\xcc7\\xc9S\\xf0\\x0f\\xfc\\xbf\\xa9\\xe3\\xf6\\xf7oJ\\xb8\\xc3\\x18\\x8f\\n\\x9c\\xb9\\x85r\\x1f0\\x9a\\r\\x0b\\xc3\\xf6\\xb7\\xff\\xf4\\xe3\\x1e\\xd7\\xffz\\xf8\\xc7\\xa9\\xfc \\xe4~\\xaf\\x81\\r\\xbb\\xd1\\x07\\xf2\\x80u\\xf4\\xff'\\xc8\\x16o(\\x0f\\xf0>\\t\\x8ao\\x8bG\\xad\\xa5\\xb5\\xdb\\x19 \\xc0\\xdb}\\xcc\\xf2\\xea\\x15z\\xb0Sz\\xc9W\\x94\\xc6\\xf8x\\xe8\\x95\\x06y\\x8c\\x0e\\x11\\xe0t\\xc5\\xb6\\xbc\\xc7\\xfa;~\\x9b\\xe2\\xa2\\xff\\xc2\\xceUF\\tp\\xda\\xf8T\\xfc\\xd0\\xad\\xbe\\x16\\xe27\\xcfo\\x98\\xe1\\x0f\\x14\\xe0\\xb8\\xff\\x0c\\xe4tz\\x1efh\\xd7\\x19h\\xf8C\\x058\\xd4\\x9a\\xf9\\xec\\xf3cc\\xd8an1\\xd6\\xe0\\x07\\x0bp`\\xfb\\xe9\\xccw\\x0e\\xc6\\xda\\xb0KF\\x1b\\xe5C?\\x11\\xfd\\x84F\\xfa\\x14\\xd5'\\xf3\\xfb\\xd3\\xe3\\rT\\x80O\\xec\\xf8\\x1b\\xdb#nk\\x01>\\xbd\\xb3_\\x97M\\t\\x90\\x94OD\\x93\\x12 )\\x01\\x92\\x12 )\\x01\\x92\\x12 )\\x01\\x92\\xf2^0\\x8f\\xf4\\xe7\\xfd\\xe7\\xcb\\xc7\\t\\x02d\\xce\\x9f\\x83\\xdf_V\\x97\\x1ezY[8\\x7f\\r\\xde\\t\\x19\\xdf\\x9fi\\x9a\\xab\\xe0\\xdf\\xb2C/\\xabK\\x0f\\xcf\\xb8)\\x94\\xbb\\x13\\xe0E\\xd6Z8\\xda\\xdc/k\\x0b\\x8f\\xce6F\\x0b\\x89\\xfb\\x07\\xf8\\xber\\x97\\xb6\\xda}\\xae\\xf6h\\x8b^\\x10\\xc3\\x0fn!\\xb15\\xc0\\xb9\\xed\\xf2\\xb2\\xb6p\\xc9\\xe7\\x16\\x96/)\\x86\\x9fa\\xf7\\xeb\\xa3\\x08[\\x9b\\xc0\\xce\\x0b\\x81\\x94\\xf4G\\xeaI_\\x07|\\x9b9m\\xf7\\xf0Qp\\xde\\xb7\\r\\xf08\\xb1\\xdd\\xd2\\x82\\xd3K\\xec>~\\x9bK\\xf2\\xd3\\xc5O\\xce\\xb0p\\xe5\\xbb\\xd3\\xb3\\\\\\x98\\xfb\\xdb\\xcaE\\xd6\\x96}{q\\x80\\x8b\\xb5L\\xd3nu\\xe9\\xcdot\\xfb\\x89W\\xdd\\xc8\\xee\\xe4\\xaaN\\x93Z\\xbb\\xb5\\xd9e3U\\xbe}:\\xf5m\\xe5\\x9c\\x83x@\\x80Wn\\xc5;\\xd5\\xf7\\xe9&\\x1e\\xb7]\\xeero\\xde\\x96\\x1a\\\\9\\xed\\xcc\\x05v+\\xa7\\xdd\\xc5=\\x03|@B\\xcfb\\x98U\\xb5^\\xef\\x87\\xd5$/\\xdbc\\xb8c\\x80\\xc3\\xacT\\x1e\\xe0m\\xf9\\xaf\\xd5\\x1a\\xbf\\xedA\\x08\\xdf\\xdbG\\xa27\\np\\x8c\\xd9\\xee\\x8aQt\\x03\\x7f;\\x98\\x19\\xae\\x1e\\xc5-v\\xcf\\xdam\\xb75\\xc0\\xb7i\\x1a\\xf9X\\xea\\xca\\xd5x\\xdbu\\x7f\\xe9\\xb5\\x8d\\xf1\\xa8\\x8d\\xad\\x06x\\xbc\\x86\\x16\\x8f\\x1a\\x7f\\xfa\\xaa\\x0c\\xef\\xff\\xf57}\\x9b\\xd7\\x98\\xceOJ\\xf3\\xe7\\xf8x]j6\\xc0\\x95\\xd7rG\\x9e\\x04\\x7f\\xa0\\xcb#\\xba\\xf5c\\xe5\\xab\\xd7\\xe7\\xbd`R\\x07\\x9f\\x86\\xd9\\xd6\\xf2\\xd9\\xb7\\xaf`\\xc6\\xdc+\\xdc\\xd3t\\xc5Q\\xf0\\x03\\xdf=\\xe0\\x89,MR\\xbb\\xcb{\\xda\\xfa\\x0e=\\x9cw\\x83}@\\xfdq\\xbd+\\x02|[y\\xd7\\x05.s\\xc5S\\xf04\\xfd}\\x1a\\x16\\x1f_te\\x80p\\x1b^\\x07$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\x02$%@R\\xff\\x017x\\xc0\\xb6\\xd3G\\xb8\\xf1\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\", shape=(), dtype=string)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(640, 512, 1), dtype=uint8, numpy=\n",
              "array([[[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        ...,\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        ...,\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       [[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        ...,\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        ...,\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        ...,\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]],\n",
              "\n",
              "       [[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        ...,\n",
              "        [1],\n",
              "        [1],\n",
              "        [1]]], dtype=uint8)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1bYkHXoCv4i"
      },
      "source": [
        "#print(train_masks)\n",
        "print(train_images)\n",
        "print(train_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-2OJmow2VhG"
      },
      "source": [
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp4GSu2r2cIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3739362e-24a5-43c5-d94c-96a8e165e639"
      },
      "source": [
        "def DeeplabV3Plus(image_size_width, image_size_height, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size_width, image_size_height, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        #weights=\"imagenet\", include_top=False, input_tensor=model_input - removed imagenet weights\n",
        "        weights=None, include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    print(\"x shape 1 value\", x.shape[1] )\n",
        "    print(\"x shape 2 value\", x.shape[2] )\n",
        "\n",
        "    print(\"size is\", image_size_width // 4 // x.shape[1], image_size_height // 4 // x.shape[2])\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size_width // 4 // x.shape[1], image_size_height // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    \n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size_width // x.shape[1], image_size_height // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "\n",
        "model = DeeplabV3Plus(image_size_width=IMAGE_SIZE_WIDTH, \n",
        "                      image_size_height=IMAGE_SIZE_HEIGHT,\n",
        "                      num_classes=NUM_CLASSES)\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape 1 value 40\n",
            "x shape 2 value 32\n",
            "size is 4 4\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 640, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 646, 518, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 320, 256, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 320, 256, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 320, 256, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 322, 258, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 160, 128, 64  0           ['pool1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 160, 128, 64  4160        ['pool1_pool[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 160, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 160, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 160, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 160, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 160, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 160, 128, 25  16640       ['pool1_pool[0][0]']             \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 160, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 160, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                       6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 160, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                       6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 160, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 160, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 160, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 160, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 160, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 160, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 160, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 160, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 160, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 160, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                       6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 160, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
            "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 160, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 160, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 160, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 160, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 160, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 160, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 160, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 160, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 160, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                       6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 160, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
            "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 160, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 80, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 80, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 80, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 80, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 80, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 80, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 80, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 80, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 80, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 80, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 80, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 80, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 80, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 80, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 80, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 80, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 80, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 80, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 80, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 80, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 80, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 80, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 80, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 80, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 80, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 80, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 80, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 80, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 80, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 80, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 80, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 80, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 80, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 80, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 80, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 80, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 80, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 80, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 80, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 80, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 80, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 80, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 40, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 40, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 40, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 40, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 40, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 40, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 40, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 40, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 40, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 40, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 40, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 40, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 40, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 40, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 40, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 40, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 40, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 40, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 40, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 40, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 40, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 40, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 40, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 40, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 40, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 40, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 40, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 40, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 40, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 40, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 40, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 40, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 40, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 40, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 40, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 40, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 256)   0           ['conv4_block6_2_relu[0][0]']    \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 1, 1, 256)    65792       ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 1, 1, 256)   1024        ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 40, 32, 256)  65536       ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 40, 32, 256)  589824      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 40, 32, 256)  589824      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 40, 32, 256)  589824      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu (TFOpLambda)        (None, 1, 1, 256)    0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 40, 32, 256)  1024       ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 40, 32, 256)  1024       ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 40, 32, 256)  1024       ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 40, 32, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 40, 32, 256)  0           ['tf.nn.relu[0][0]']             \n",
            "                                                                                                  \n",
            " tf.nn.relu_1 (TFOpLambda)      (None, 40, 32, 256)  0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.relu_2 (TFOpLambda)      (None, 40, 32, 256)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.relu_3 (TFOpLambda)      (None, 40, 32, 256)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.relu_4 (TFOpLambda)      (None, 40, 32, 256)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 40, 32, 1280  0           ['up_sampling2d[0][0]',          \n",
            "                                )                                 'tf.nn.relu_1[0][0]',           \n",
            "                                                                  'tf.nn.relu_2[0][0]',           \n",
            "                                                                  'tf.nn.relu_3[0][0]',           \n",
            "                                                                  'tf.nn.relu_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 40, 32, 256)  327680      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 40, 32, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 160, 128, 48  3072        ['conv2_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_5 (TFOpLambda)      (None, 40, 32, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 160, 128, 48  192        ['conv2d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 160, 128, 25  0          ['tf.nn.relu_5[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " tf.nn.relu_6 (TFOpLambda)      (None, 160, 128, 48  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 160, 128, 30  0           ['up_sampling2d_1[0][0]',        \n",
            "                                4)                                'tf.nn.relu_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 160, 128, 25  700416      ['concatenate_1[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 160, 128, 25  1024       ['conv2d_7[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " tf.nn.relu_7 (TFOpLambda)      (None, 160, 128, 25  0           ['batch_normalization_7[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 160, 128, 25  589824      ['tf.nn.relu_7[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 160, 128, 25  1024       ['conv2d_8[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " tf.nn.relu_8 (TFOpLambda)      (None, 160, 128, 25  0           ['batch_normalization_8[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 640, 512, 25  0          ['tf.nn.relu_8[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 640, 512, 7)  1799        ['up_sampling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,853,895\n",
            "Trainable params: 11,821,159\n",
            "Non-trainable params: 32,736\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jv41GSo2fm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1aa430eb-8f29-4ec1-93c1-5beae8d275ca"
      },
      "source": [
        "#### This is the training cell\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "my_callbacks = [\n",
        "    #tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/Logs/Unet-7classes-finalpapersubmission'),\n",
        "    #keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/deeplab/deeplab-finalpapersubmission-20201only\", save_freq = 'epoch', save_best_only=True)\n",
        "    #keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only\", save_freq = 'epoch', save_best_only=True)\n",
        "    keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled\", save_freq = 'epoch', save_best_only=True)\n",
        "]\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, callbacks = my_callbacks, epochs=25)\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.ylabel(\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.ylabel(\"val_accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "#model.save(\"/content/drive/MyDrive/Models/deeplab/deeplab-finalpapersubmission-2020only\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.9444INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 2034s 541ms/step - loss: 0.1674 - accuracy: 0.9444 - val_loss: 0.1056 - val_accuracy: 0.9629\n",
            "Epoch 2/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9666INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 2017s 541ms/step - loss: 0.0949 - accuracy: 0.9666 - val_loss: 0.0795 - val_accuracy: 0.9713\n",
            "Epoch 3/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9742INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 1958s 526ms/step - loss: 0.0720 - accuracy: 0.9742 - val_loss: 0.0605 - val_accuracy: 0.9780\n",
            "Epoch 4/25\n",
            "3725/3725 [==============================] - 1987s 534ms/step - loss: 0.0584 - accuracy: 0.9787 - val_loss: 0.0633 - val_accuracy: 0.9775\n",
            "Epoch 5/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9815INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 2019s 542ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 0.0486 - val_accuracy: 0.9820\n",
            "Epoch 6/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9835INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 2019s 542ms/step - loss: 0.0437 - accuracy: 0.9835 - val_loss: 0.0447 - val_accuracy: 0.9832\n",
            "Epoch 7/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9850INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 2017s 541ms/step - loss: 0.0389 - accuracy: 0.9850 - val_loss: 0.0412 - val_accuracy: 0.9845\n",
            "Epoch 8/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9857INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 1963s 527ms/step - loss: 0.0371 - accuracy: 0.9857 - val_loss: 0.0379 - val_accuracy: 0.9856\n",
            "Epoch 9/25\n",
            "3725/3725 [==============================] - 1988s 534ms/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.0400 - val_accuracy: 0.9851\n",
            "Epoch 10/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9875INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 2019s 542ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0333 - val_accuracy: 0.9870\n",
            "Epoch 11/25\n",
            "3725/3725 [==============================] - 1930s 518ms/step - loss: 0.0299 - accuracy: 0.9880 - val_loss: 0.0350 - val_accuracy: 0.9866\n",
            "Epoch 12/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9887INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 2019s 542ms/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 0.0303 - val_accuracy: 0.9880\n",
            "Epoch 13/25\n",
            "3725/3725 [==============================] - 1986s 533ms/step - loss: 0.0275 - accuracy: 0.9890 - val_loss: 0.0312 - val_accuracy: 0.9878\n",
            "Epoch 14/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9896INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3725/3725 [==============================] - 2019s 542ms/step - loss: 0.0256 - accuracy: 0.9896 - val_loss: 0.0286 - val_accuracy: 0.9886\n",
            "Epoch 15/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9899INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3725/3725 [==============================] - 2017s 541ms/step - loss: 0.0249 - accuracy: 0.9899 - val_loss: 0.0285 - val_accuracy: 0.9888\n",
            "Epoch 16/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9899INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3725/3725 [==============================] - 2020s 542ms/step - loss: 0.0249 - accuracy: 0.9899 - val_loss: 0.0273 - val_accuracy: 0.9891\n",
            "Epoch 17/25\n",
            "3725/3725 [==============================] - 1990s 534ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 0.0295 - val_accuracy: 0.9884\n",
            "Epoch 18/25\n",
            "3725/3725 [==============================] - 1990s 534ms/step - loss: 0.0224 - accuracy: 0.9908 - val_loss: 0.0280 - val_accuracy: 0.9891\n",
            "Epoch 19/25\n",
            "3725/3725 [==============================] - 1990s 534ms/step - loss: 0.0209 - accuracy: 0.9913 - val_loss: 0.0282 - val_accuracy: 0.9890\n",
            "Epoch 20/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9913INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3725/3725 [==============================] - 2021s 543ms/step - loss: 0.0211 - accuracy: 0.9913 - val_loss: 0.0260 - val_accuracy: 0.9897\n",
            "Epoch 21/25\n",
            "3725/3725 [==============================] - 1931s 518ms/step - loss: 0.0199 - accuracy: 0.9917 - val_loss: 0.0266 - val_accuracy: 0.9896\n",
            "Epoch 22/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9915INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3725/3725 [==============================] - 2021s 542ms/step - loss: 0.0207 - accuracy: 0.9915 - val_loss: 0.0254 - val_accuracy: 0.9900\n",
            "Epoch 23/25\n",
            "3725/3725 [==============================] - 1989s 534ms/step - loss: 0.0186 - accuracy: 0.9922 - val_loss: 0.0259 - val_accuracy: 0.9899\n",
            "Epoch 24/25\n",
            "3725/3725 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9921INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3725/3725 [==============================] - 2021s 542ms/step - loss: 0.0188 - accuracy: 0.9921 - val_loss: 0.0251 - val_accuracy: 0.9900\n",
            "Epoch 25/25\n",
            "3725/3725 [==============================] - 1989s 534ms/step - loss: 0.0183 - accuracy: 0.9924 - val_loss: 0.0261 - val_accuracy: 0.9897\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c22OwPuNCad7"
      },
      "source": [
        "## this is to retrain the saved model - RUN#2\n",
        "reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled\")\n",
        "print(\"model loaded\")\n",
        "\n",
        "my_callbacks = [\n",
        "    #tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/Logs/Unet-7classes-finalpapersubmission'),\n",
        "    keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/deeplab/deeplab-7classes-finalpapersubmission_2019&2020_shuffled\", save_freq = 'epoch', save_best_only=True)\n",
        "\n",
        "               ]\n",
        "\n",
        "history = reconstructed_model.fit(train_dataset, validation_data=val_dataset, callbacks = my_callbacks, epochs=50)\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.ylabel(\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.ylabel(\"val_accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "#commented below as checkpoint already has save best. else it will create a duplicate\n",
        "#print(\"model to be saved\")\n",
        "#reconstructed_model.save(\"/content/drive/MyDrive/Models/deeplab/deeplab-finalpapersubmission-2020only\")\n",
        "#print(\"model saved\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}