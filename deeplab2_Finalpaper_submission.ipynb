{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplab2-Finalpaper_submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKP/POo40LYgJlg9ux/Yvm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssnirgudkar/Datasetpaper-final/blob/main/deeplab2_Finalpaper_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW3lSbsBxFzp"
      },
      "source": [
        "## Use this version as the most final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GKo9sXGKeri"
      },
      "source": [
        "to do - \n",
        "1. Batch size should be 10 (identical with UNet, PSPNet) - This batch size gives OOM. 7 is the max we can go with regular RAM\n",
        "2. Image size 512*512 : Is this really needed? We are not using imagenet weights anyway. - Updted to use the actual \n",
        "3. Shuffle the training and validation images. Use the code which was shared earlier. I think this will be beneficial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoAs-oCSzGI6"
      },
      "source": [
        "## we have to keep batchsize = 2 or more. It does not run with batch size 1. Image will be resized to 512*512\n",
        "## mask datatype is uint8. segments.ai semantic masks are uint8 and instance masks are uint16. We need to be careful about which type of masks are getting processed else it reads masks as 0. \n",
        "##the resize was changed to nearest. but we can check if thats needed. bilinear is default. So we can try to keep it as bilinera and that shld also work. With this run, objects were not coming up well. objects and background was getting mixed\n",
        "\n",
        "Run2 11/11 - Uncommented the 127.5-1 code. so now both image and masks are float 32. also changed the nearest back to bilnear. changed the batch size from 10 to 4. running with 50 epochs to see how it works.\n",
        "\n",
        "Train images - \n",
        "Val images - \n",
        "Test images \n",
        "Epochs - 500 \n",
        "Train time -\n",
        "\n",
        "##Run3 - \n",
        "Train images - 3438\n",
        "Val images - 982\n",
        "Test images - 492\n",
        "Epochs - 50 \n",
        "Train time - 3 hrs 49 min\n",
        "Test time - \n",
        "Any preloaded weights - NO. Imagenet weights are not used\n",
        "The masks are uint8. the code had it as uint16. Hence we were getting pixel values of 257. fixed that\n",
        "Model - deeplab-finalpapersubmission_V1\n",
        "\n",
        "##Run4 - \n",
        "Train images - 26081\n",
        "Val images - 7452\n",
        "Test images - 3726\n",
        "Epochs - 25(will break into 4 parts as this is a big dataset.  \n",
        "Train time - 10 hrs 40 min\n",
        "Test time - \n",
        "Any preloaded weights - NO. Imagenet weights are not used\n",
        "Model - deeplab-finalpapersubmission (the next ones will be submission2,3 and 4)\n",
        "infernce folder - IRDatasetFinal-Inferences\n",
        "loss: 0.0623 - accuracy: 0.9790 \n",
        "\n",
        "##Run5 - 2020 & 2021\n",
        "loss: 0.0361 - accuracy: 0.9873 - val_loss: 3.3841 - val_accuracy: 0.7209\n",
        "epochs - 50 \n",
        "ran with 2020 and 2021 dataset only \n",
        "Model - deeplab folder - deeplab-finalpapersubmission-2020only (there's another with 2020-only. need to check)\n",
        "training time - 9 hrs, 27 min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaETn9Z21S9y"
      },
      "source": [
        "# https://keras.io/examples/vision/deeplabv3_plus/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl9XF-Fty5RZ",
        "outputId": "0ab32b73-d9b2-4e78-8262-c7dd89dba91b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetConsolidated/train.zip\", \"r\")\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/train.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/trainannot.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/val.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/valannot.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "'''\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/test.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/testannot.zip\", \"r\")\n",
        "zip_ref.extractall(\"/content/IRDatasetFinal\")\n",
        "zip_ref.close()\n",
        "'''"
      ],
      "metadata": {
        "id": "ClQ6pwk4y6Cv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c479cedf-128b-4396-e29c-1cf78bd7e9ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nzip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/test.zip\", \"r\")\\nzip_ref.extractall(\"/content/IRDatasetFinal\")\\nzip_ref.close()\\n\\nzip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/IRDatasetAfter2019/testannot.zip\", \"r\")\\nzip_ref.extractall(\"/content/IRDatasetFinal\")\\nzip_ref.close()\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "APP_FOLDER = '/content/IRDatasetFinal/train'\n",
        "totalFiles = 0\n",
        "totalDir = 0\n",
        "\n",
        "for base, dirs, files in os.walk(APP_FOLDER):\n",
        "    print('Searching in : ',base)\n",
        "    for directories in dirs:\n",
        "        totalDir += 1\n",
        "    for Files in files:\n",
        "        totalFiles += 1\n",
        "   \n",
        "\n",
        "print('Total number of files',totalFiles)\n",
        "print('Total Number of directories',totalDir)\n",
        "print('Total:',(totalDir + totalFiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LrEwKPVy545",
        "outputId": "cb82c77e-2561-4f1d-f0f2-93f2641f3f54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching in :  /content/IRDatasetFinal/train\n",
            "Total number of files 10562\n",
            "Total Number of directories 0\n",
            "Total: 10562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "675_gYSZ1X9M"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83c9SFcwp5dM"
      },
      "source": [
        "Downloading the data We will use the Crowd Instance-level Human Parsing Dataset for training our model. The Crowd Instance-level Human Parsing (CIHP) dataset has 38,280 diverse human images. Each image in CIHP is labeled with pixel-wise annotations for 20 categories, as well as instance-level identification. This dataset can be used for the \"human part segmentation\" task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4GnbNOS1gOo"
      },
      "source": [
        "#!gdown https://drive.google.com/uc?id=1B9A9UCJYMwTL4oBEo4RZfbMZMaZhKJaz\n",
        "#!unzip -q instance-level-human-parsing.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGYmazAh-FGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49cd14d6-8d14-4601-920a-450cb66f6c23"
      },
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "# to copy files from google drive to colab memory\n",
        "#%cp -av /content/drive/MyDrive/TheIRDatasetMini/ TheIRDatasetMini\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D60VHKzY2QWn"
      },
      "source": [
        "IMAGE_SIZE_WIDTH = 640\n",
        "IMAGE_SIZE_HEIGHT = 512\n",
        "BATCH_SIZE = 7\n",
        "NUM_CLASSES = 7\n",
        "#DATA_DIR = '/content/drive/MyDrive/TheIRDatasetMini_backup'\n",
        "DATA_DIR = '/content/IRDatasetFinal'\n",
        "#DATA_DIR = '/content/drive/MyDrive/TheIRDataset'\n",
        "#DATA_DIR = '/content/drive/MyDrive/IR -test'\n",
        "\n",
        "#VAL_DATA_DIR = \"./instance-level_human_parsing/instance-level_human_parsing/Training\"\n",
        "#NUM_TRAIN_IMAGES = 80\n",
        "#NUM_VAL_IMAGES = 10\n",
        "\n",
        "'''\n",
        "train_images = sorted(glob(os.path.join(DATA_DIR, \"train/*\")))[:NUM_TRAIN_IMAGES]\n",
        "train_masks = sorted(glob(os.path.join(DATA_DIR, \"trainannot/*\")))[:NUM_TRAIN_IMAGES]\n",
        "val_images = sorted(glob(os.path.join(DATA_DIR, \"train/*\")))[\n",
        "    NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES\n",
        "]\n",
        "val_masks = sorted(glob(os.path.join(DATA_DIR, \"trainannot/*\")))[\n",
        "    NUM_TRAIN_IMAGES : NUM_VAL_IMAGES + NUM_TRAIN_IMAGES\n",
        "]\n",
        "'''\n",
        "train_images = sorted(glob(os.path.join(DATA_DIR, \"train/*\"))) \n",
        "train_masks = sorted(glob(os.path.join(DATA_DIR, \"trainannot/*\"))) \n",
        "indices_train = random.sample(range(len(train_images)), len(train_images))\n",
        "train_images = list(map(train_images.__getitem__, indices_train))\n",
        "train_masks = list(map(train_masks.__getitem__, indices_train))\n",
        "print(\"type of train_images = \", type(train_images))\n",
        "\n",
        "val_images = sorted(glob(os.path.join(DATA_DIR, \"val/*\")))\n",
        "val_masks = sorted(glob(os.path.join(DATA_DIR, \"valannot/*\")))\n",
        "indices_val = random.sample(range(len(val_images)), len(val_images))\n",
        "val_images = list(map(val_images.__getitem__, indices_val))\n",
        "val_masks = list(map(val_masks.__getitem__, indices_val))\n",
        "\n",
        "#test_images = sorted(glob(os.path.join(DATA_DIR, \"test/*\")))\n",
        "#test_masks = sorted(glob(os.path.join(DATA_DIR, \"testannot/*\")))\n",
        "\n",
        "\n",
        "def read_image(image_path, mask=False):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    print(\"image=\", image)\n",
        "    if mask:\n",
        "        image = tf.image.decode_png(image, channels=0, dtype=tf.uint8)\n",
        "        #print(\"mask 1st read\", image)\n",
        "        #print(\"Max value of mask as per tef.reduce are\", tf.reduce_max(image))\n",
        "        image.set_shape([None, None, 1])\n",
        "        #image = tf.cast(image, dtype=tf.float32)\n",
        "        #print(\"mask 2nd read\", image)\n",
        "        image = tf.image.resize(images=image, method= 'nearest', size=[IMAGE_SIZE_WIDTH, IMAGE_SIZE_HEIGHT])\n",
        "        #print(\"mask 3rd read after resize\", image)\n",
        "        #print('final image' ,image)\n",
        "        #print('unique values of tensor' , tf.unique(image))\n",
        "    else:\n",
        "        image = tf.image.decode_png(image, channels=3, dtype=tf.uint8)\n",
        "        #print(\"1st step in read image\", image)\n",
        "        image.set_shape([None, None, 3])\n",
        "        image = tf.cast(image, dtype=tf.float32)\n",
        "        #print(\"2nd step in read image\", image)\n",
        "        image = tf.image.resize(images=image, method= 'bilinear', size=[IMAGE_SIZE_WIDTH, IMAGE_SIZE_HEIGHT])\n",
        "        image = image / 127.5 - 1\n",
        "        #print(\"image looks like\", image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_data(image_list, mask_list):\n",
        "    image = read_image(image_list)\n",
        "    mask = read_image(mask_list, mask=True)\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def data_generator(image_list, mask_list):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_dataset = data_generator(train_images, train_masks)\n",
        "val_dataset = data_generator(val_images, val_masks)\n",
        "\n",
        "read_image(train_masks[20], mask=True)\n",
        "\n",
        "#print ((np.unique(cv2.imread(train_masks[1],cv2.IMREAD_UNCHANGED))))\n",
        "\n",
        "\n",
        "#print(\"Train Dataset:\", train_dataset)\n",
        "#print(\"Val Dataset:\", val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1bYkHXoCv4i"
      },
      "source": [
        "#print(train_masks)\n",
        "print(train_images)\n",
        "print(train_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-2OJmow2VhG"
      },
      "source": [
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp4GSu2r2cIi"
      },
      "source": [
        "def DeeplabV3Plus(image_size_width, image_size_height, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size_width, image_size_height, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        #weights=\"imagenet\", include_top=False, input_tensor=model_input - removed imagenet weights\n",
        "        weights=None, include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    print(\"x shape 1 value\", x.shape[1] )\n",
        "    print(\"x shape 2 value\", x.shape[2] )\n",
        "\n",
        "    print(\"size is\", image_size_width // 4 // x.shape[1], image_size_height // 4 // x.shape[2])\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size_width // 4 // x.shape[1], image_size_height // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    \n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size_width // x.shape[1], image_size_height // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "\n",
        "model = DeeplabV3Plus(image_size_width=IMAGE_SIZE_WIDTH, \n",
        "                      image_size_height=IMAGE_SIZE_HEIGHT,\n",
        "                      num_classes=NUM_CLASSES)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jv41GSo2fm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d18731-b53f-447d-9e72-c749ad7db90c"
      },
      "source": [
        "#### This is the training cell\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "my_callbacks = [\n",
        "    #tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/Logs/Unet-7classes-finalpapersubmission'),\n",
        "    #keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/deeplab/deeplab-finalpapersubmission-20201only\", save_freq = 'epoch', save_best_only=True)\n",
        "    keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only\", save_freq = 'epoch', save_best_only=True)\n",
        "]\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, callbacks = my_callbacks, epochs=25)\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.ylabel(\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.ylabel(\"val_accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "#plt.show()\n",
        "\n",
        "#model.save(\"/content/drive/MyDrive/Models/deeplab/deeplab-finalpapersubmission-2020only\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1508/1508 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9407INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1508/1508 [==============================] - 766s 505ms/step - loss: 0.1741 - accuracy: 0.9407 - val_loss: 0.2330 - val_accuracy: 0.9268\n",
            "Epoch 2/25\n",
            "1508/1508 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9633INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1508/1508 [==============================] - 760s 504ms/step - loss: 0.1027 - accuracy: 0.9633 - val_loss: 0.1086 - val_accuracy: 0.9613\n",
            "Epoch 3/25\n",
            "1508/1508 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9716INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1508/1508 [==============================] - 760s 504ms/step - loss: 0.0780 - accuracy: 0.9716 - val_loss: 0.0808 - val_accuracy: 0.9705\n",
            "Epoch 4/25\n",
            "1508/1508 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9756INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1508/1508 [==============================] - 760s 504ms/step - loss: 0.0664 - accuracy: 0.9756 - val_loss: 0.0551 - val_accuracy: 0.9793\n",
            "Epoch 5/25\n",
            "1508/1508 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9793INFO:tensorflow:Assets written to: /content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1508/1508 [==============================] - 760s 504ms/step - loss: 0.0556 - accuracy: 0.9793 - val_loss: 0.0467 - val_accuracy: 0.9825\n",
            "Epoch 6/25\n",
            "1034/1508 [===================>..........] - ETA: 3:37 - loss: 0.0544 - accuracy: 0.9797"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c22OwPuNCad7"
      },
      "source": [
        "## this is to retrain the saved model - RUN#2\n",
        "reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only\")\n",
        "print(\"model loaded\")\n",
        "\n",
        "my_callbacks = [\n",
        "    #tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/Logs/Unet-7classes-finalpapersubmission'),\n",
        "    keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/deeplab/deeplab-revisedcode-2020only\", save_freq = 'epoch', save_best_only=True)\n",
        "\n",
        "               ]\n",
        "\n",
        "history = reconstructed_model.fit(train_dataset, validation_data=val_dataset, callbacks = my_callbacks, epochs=50)\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.ylabel(\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.ylabel(\"val_accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "#commented below as checkpoint already has save best. else it will create a duplicate\n",
        "#print(\"model to be saved\")\n",
        "#reconstructed_model.save(\"/content/drive/MyDrive/Models/deeplab/deeplab-finalpapersubmission-2020only\")\n",
        "#print(\"model saved\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}